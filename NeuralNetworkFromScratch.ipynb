{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully Connected Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***The notebook contains the code of a 3-layer (input - hidden - output) neural network with backpropagation for my course project.***<br>\n",
    "***I will apply the Neural Network model to the MINST dataset to test its performace.***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random \n",
    "import warnings\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "warnings.filterwarnings(\"ignore\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "Then we wil load the MINST data from sklearn and split the data into train and test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# extract data with tensorflow API\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\")\n",
    "mnist_train_images = mnist.train.images\n",
    "mnist_train_labels = mnist.train.labels\n",
    "mnist_test_images = mnist.test.images\n",
    "mnist_test_labels = mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(55000, 784)\n",
      "(10000, 784)\n",
      "(55000,)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(type(mnist_train_images))\n",
    "print(mnist_train_images.shape)\n",
    "print(mnist_test_images.shape)\n",
    "print(mnist_train_labels.shape)\n",
    "print(mnist_test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We have to do the one-hot-encoding on the labels and scale the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# scale\n",
    "scaler = MinMaxScaler(feature_range=(0,1), copy = True)\n",
    "scale_input = np.concatenate([mnist_train_images,mnist_test_images],axis = 0)\n",
    "minst_scale = scaler.fit_transform(scale_input)\n",
    "\n",
    "# retrieve the data\n",
    "X_train = minst_scale[:mnist_train_images.shape[0],]\n",
    "X_test = minst_scale[mnist_train_images.shape[0]:,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = [X_train[i,] for i in range(X_train.shape[0])]\n",
    "X_test = [X_test[i,] for i in range(X_test.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# onehotencode of labels\n",
    "y_train = []\n",
    "for i in mnist_train_labels:\n",
    "    encode = np.zeros(10)\n",
    "    encode[i] = 1\n",
    "    y_train.append(encode)\n",
    "\n",
    "y_test = []\n",
    "for i in mnist_test_labels:\n",
    "    encode = np.zeros(10)\n",
    "    encode[i] = 1\n",
    "    y_test.append(encode)\n",
    "\n",
    "# create train test data sets\n",
    "train = [k for k in zip(X_train, y_train)]\n",
    "test = [k for k in zip(X_test, y_test)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A nueral network class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class NeuralNet(object):\n",
    "    \n",
    "    \n",
    "    def __init__(self,size):\n",
    "        \"\"\"\n",
    "        Initialize w with small random gaussian\n",
    "        \"\"\"\n",
    "\n",
    "        self.size = size\n",
    "        self.depth = len(size)\n",
    "        self.biases = [np.random.rand(x,1) for x in self.size[1:]]\n",
    "        self.weights = [np.zeros([x,y]) for x,y in zip(self.size[1:], self.size[:-1])]\n",
    "    \n",
    "    def fit(self, train, test = None, num_epoch = 10, batch_size = 100, learn_rate = 1.0):\n",
    "        \"\"\"\n",
    "        The fit method shuffle the train data and create the batches.\n",
    "        Then it update the weights and bias with stochastic gradient descent\n",
    "        and returns the training error on test dataset after each epoch\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        n_train = len(train)\n",
    "        n_test = len(test)\n",
    "        i = 0\n",
    "        \n",
    "        if test:\n",
    "            for i in range(num_epoch):\n",
    "                random.shuffle(train)\n",
    "                batches = [train[k:k+batch_size] for k in np.arange(0, n_train, batch_size)]\n",
    "                \n",
    "                for batch in batches:\n",
    "                    self.update(batch, learn_rate)\n",
    "                i += 1\n",
    "                print(\"Prediction accuracy on test data after epoch {} is: {}\".format(i, \n",
    "                        self.evaluate(test)/n_test))\n",
    "        \n",
    "    def update(self, batch, learn_rate):\n",
    "        \"\"\"\n",
    "        Update the parameters in each minibatch\n",
    "        \"\"\"\n",
    "        \n",
    "        batch_length = len(batch)\n",
    "        weight_change = [np.zeros(weight.shape) for weight in self.weights]\n",
    "        bias_change = [np.zeros(bias.shape) for bias in self.biases]\n",
    "        \n",
    "        # accumulate parameter gradient\n",
    "        for i in range(batch_length):\n",
    "            delta_weight, delta_bias = self.backpropagation(batch[i])\n",
    "            weight_change = [x+y for x,y in zip(weight_change, delta_weight)]\n",
    "            bias_change = [x+y for x,y in zip(bias_change, delta_bias)]\n",
    "        \n",
    "        # update the weights and bias for a mini-batch\n",
    "        self.weights = [x-(learn_rate/batch_length) * y for x, y in zip(self.weights, weight_change)]\n",
    "        self.biases = [x-(learn_rate/batch_length) * y for x, y in zip(self.biases, bias_change)]\n",
    "        \n",
    "    def backpropagation(self, one_sample):\n",
    "        \"\"\"\n",
    "        This function takes in one sample and return the gradient of \n",
    "        cost function of each layer with backpropagation\n",
    "        \"\"\"\n",
    "        \n",
    "        x = one_sample[0]\n",
    "        x.shape = (len(x),1)\n",
    "        y = one_sample[1]\n",
    "        y.shape = (len(y),1)\n",
    "        \n",
    "        weight_container = [np.zeros(weight.shape) for weight in self.weights]\n",
    "        bias_container = [np.zeros(bias.shape) for bias in self.biases]\n",
    "        \n",
    "        # forward\n",
    "        # hidden layer\n",
    "        z1 = np.dot(self.weights[0], x) + self.biases[0]\n",
    "        output1 = self.sigmoid(z1)\n",
    "        \n",
    "        # output layer\n",
    "        z2 = np.dot(self.weights[1], output1) + self.biases[1]\n",
    "        output2 = self.softmax(z2)\n",
    "        \n",
    "        # gradient of cost\n",
    "        delta2 = output2 - y\n",
    "        \n",
    "        # backward propagated to hidden layer\n",
    "        bias_container[-1] = delta2\n",
    "        weight_container[-1] = np.dot(delta2, output1.transpose())\n",
    "        \n",
    "        # backward propagated to hidden layer\n",
    "        r = self.sigmoid_dev(z1)\n",
    "        delta1 = np.dot(self.weights[-1].transpose(), delta2) * r\n",
    "        bias_container[-2] = delta1\n",
    "        weight_container[-2] = np.dot(delta1, x.transpose())\n",
    "        return (weight_container, bias_container)\n",
    "        \n",
    "    def predict(self, x):\n",
    "        \"\"\"\n",
    "        return vector indicating estimated class of x\n",
    "        \"\"\"\n",
    "        \n",
    "        x.shape = (len(x),1)\n",
    "        z1 = np.dot(self.weights[0], x) + self.biases[0]\n",
    "        output1 = self.sigmoid(z1)\n",
    "        z2 = np.dot(self.weights[1], output1) + self.biases[1]\n",
    "        output2 = self.softmax(z2)\n",
    "        output = np.argmax(output2)\n",
    "        return output\n",
    "        \n",
    "    def evaluate(self, test):\n",
    "        \"\"\"\n",
    "        This function will evaluate the accuracy of prediction of Neural Network\n",
    "        \"\"\"\n",
    "        \n",
    "        output = [(self.predict(x), np.argmax(y)) for (x, y) in test]\n",
    "        return sum(int(x == y) for (x, y) in output)\n",
    "        \n",
    "    # activation functions and derivatives\n",
    "    def softmax(self, z):\n",
    "        output = np.exp(z)/np.sum(np.exp(z))\n",
    "        return output\n",
    "    \n",
    "    def sigmoid(self,z):\n",
    "        return 1.0/(1.0+np.exp(-z))\n",
    "    \n",
    "    def sigmoid_dev(self,z):\n",
    "        return self.sigmoid(z)*(1-self.sigmoid(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Network = NeuralNet([784, 30, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction accuracy on test data after epoch 1 is: 0.9156\n",
      "Prediction accuracy on test data after epoch 2 is: 0.9305\n",
      "Prediction accuracy on test data after epoch 3 is: 0.9417\n",
      "Prediction accuracy on test data after epoch 4 is: 0.9433\n",
      "Prediction accuracy on test data after epoch 5 is: 0.9468\n",
      "Prediction accuracy on test data after epoch 6 is: 0.9514\n",
      "Prediction accuracy on test data after epoch 7 is: 0.9553\n",
      "Prediction accuracy on test data after epoch 8 is: 0.9556\n",
      "Prediction accuracy on test data after epoch 9 is: 0.9569\n",
      "Prediction accuracy on test data after epoch 10 is: 0.9618\n",
      "Prediction accuracy on test data after epoch 11 is: 0.9596\n",
      "Prediction accuracy on test data after epoch 12 is: 0.9608\n",
      "Prediction accuracy on test data after epoch 13 is: 0.9624\n",
      "Prediction accuracy on test data after epoch 14 is: 0.9624\n",
      "Prediction accuracy on test data after epoch 15 is: 0.9634\n",
      "Prediction accuracy on test data after epoch 16 is: 0.9612\n",
      "Prediction accuracy on test data after epoch 17 is: 0.9631\n",
      "Prediction accuracy on test data after epoch 18 is: 0.9634\n",
      "Prediction accuracy on test data after epoch 19 is: 0.9639\n",
      "Prediction accuracy on test data after epoch 20 is: 0.9627\n",
      "Prediction accuracy on test data after epoch 21 is: 0.963\n",
      "Prediction accuracy on test data after epoch 22 is: 0.964\n",
      "Prediction accuracy on test data after epoch 23 is: 0.9636\n",
      "Prediction accuracy on test data after epoch 24 is: 0.9649\n",
      "Prediction accuracy on test data after epoch 25 is: 0.9646\n",
      "Prediction accuracy on test data after epoch 26 is: 0.9644\n",
      "Prediction accuracy on test data after epoch 27 is: 0.9651\n",
      "Prediction accuracy on test data after epoch 28 is: 0.964\n",
      "Prediction accuracy on test data after epoch 29 is: 0.9638\n",
      "Prediction accuracy on test data after epoch 30 is: 0.9638\n"
     ]
    }
   ],
   "source": [
    "Network.fit(train = train, test = test, num_epoch = 30, batch_size = 10, learn_rate = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bingo, the accuracy reaches 96%.<br>\n",
    "Next, I will try to add more activation functions like Relu, and rebuild the backpropagation method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
